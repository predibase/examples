{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72d1bd65-74a3-4171-86e1-8f7180bd1712",
   "metadata": {},
   "source": [
    "# Fine-tuning LLaMa2 🦙\n",
    "\n",
    "In this demonstration, we show how to use the Predibase SDK to fine tune LLaMa2-7B. We give a detailed walkthrough of all the components required for setup and how to work in sync with the UI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e9a9860-3d0f-4339-8eb0-b3f7a6ee2b00",
   "metadata": {},
   "source": [
    "## Authentication 🔐\n",
    "\n",
    "The first step is to sign into Predibase. \n",
    "\n",
    "- If you do not have a Predibase account set up yet, you may sign up for a free account [here](https://predibase.com/free-trial)\n",
    "- If you already have an account, navigate to Settings -> My Profile and generate a new API token.\n",
    "- Finally, plug in the generated API token in the code below to authenticate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb23c51b-1d37-4590-a766-10dd1e030ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from predibase import PredibaseClient\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "pc = PredibaseClient(\n",
    "    token=\"YOUR TOKEN HERE\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81c01d1-cfb9-4010-a0ae-d15f60f3c3b0",
   "metadata": {},
   "source": [
    "## Dataset 📄\n",
    "\n",
    "Next we'll get the dataset we need to train the model. For this demonstration, we will be using the [Consumer Complaints dataset](https://www.kaggle.com/datasets/selener/consumer-complaint-database) from Kaggle. We have already uploaded this dataset to Predibase, so we just need to get it. If you need help connecting a dataset to Predibase, the [connections](https://docs.predibase.com/sdk-guide/connections/) and [datasets](https://docs.predibase.com/sdk-guide/datasets/) docs are a great resource!\n",
    "\n",
    "This dataset contains real world complaints received about financial products and services. We will be fine-tuning the model to classify the issue type of written complaint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bb61ef-7d46-4c1a-b0a6-82cafae8f592",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_complaints_dataset = pc.get_dataset(\n",
    "    dataset_name=\"DATASET NAME IN PREDIBASE\",\n",
    "    connection_name=\"CONNECTION NAME IN PREDIBASE\"\n",
    ")\n",
    "consumer_complaints_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcf8e88-3e75-4c5f-a294-366ab00db69e",
   "metadata": {},
   "source": [
    "## Engine 🚂\n",
    "\n",
    "At Predibase, engines are our solution to common compute and infrastructure pain points that everyone runs into while training models. These are problems like:\n",
    "- Encountering Out of Memory errors due to insufficient compute\n",
    "- Challenges distributing a model training job over multiple compute resources\n",
    "- Losing progress when transient issues interrupt the training process\n",
    "\n",
    "Predibase training engines mitigate these issues by:\n",
    "- Analyzing the training job details to assign the right amount of compute\n",
    "- Logic to distribute the training job over the assigned compute resources\n",
    "- Retry logic when things go wrong\n",
    "\n",
    "With this in mind, we will select the engine we want to use for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0483683c-2950-4d77-a4d6-d5283337c8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_engine = pc.get_engine(\"train_engine\")\n",
    "train_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130477f1-355b-4423-9211-b3427ab55904",
   "metadata": {},
   "source": [
    "## Model Training 🏁\n",
    "\n",
    "Now we can kick off our fine-tuning job! \n",
    "\n",
    "All we need to do is specify the LLM that we will be fine tuning and create a template telling the LLM the task to complete. Then we call `llm.finetune()` and we're on our way.\n",
    "\n",
    "\n",
    "You can follow the link in the output to track the model's progress in the UI!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41db068-e1b6-4847-b837-8bc40690a6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = pc.LLM(\"hf://meta-llama/Llama-2-7b-hf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06634691-a8fb-459b-8c90-0bcdd9d90eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_complaints_finetuning_template = \"\"\"\n",
    "    Given the following real world consumer complaint received about a financial product or service, classify the issue type: \n",
    "    Consumer Complaint: {Consumer complaint narrative} \n",
    "    Product: {Product} \n",
    "    Sub-Product: {Sub-product} \n",
    "    Issue Type:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0008e6b-68c7-4f30-8f71-7938ba4bacf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fine_tuning_job = llm.finetune(\n",
    "    prompt_template=consumer_complaints_finetuning_template,\n",
    "    target=\"Issue\",\n",
    "    dataset=consumer_complaints_dataset,\n",
    "    engine=train_engine,\n",
    "    repo=\"Fine-tuning Consumer Complaints\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b2da8f-dc36-490c-a418-52f3066d469f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Advanced Configuration 📝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d610c8d-2e19-464a-913c-cd6228752363",
   "metadata": {},
   "source": [
    "Like everything in Predibase, you have a tremendous amount of control if you want to configure it (otherwise, we do it for you). Below is a yaml config for a fine-tuning job with some of the cool features that can improve the training process!\n",
    "\n",
    "```\n",
    "model_type: llm\n",
    "base_model: meta-llama/Llama-2-7b-hf\n",
    "\n",
    "quantization:\n",
    "  bits: 4\n",
    "\n",
    "adapter:\n",
    "  type: lora\n",
    "\n",
    "prompt:\n",
    "  template: >-\n",
    "    Given the following real world consumer complaint received about a financial\n",
    "    product or service, classify the issue type: \n",
    "    Consumer Complaint: {Consumer complaint narrative} \n",
    "    Product: {Product} \n",
    "    Sub-Product: {Sub-product} \n",
    "    Issue Type:\n",
    "\n",
    "input_features:\n",
    "  - name: Consumer complaint narrative\n",
    "    type: text\n",
    "\n",
    "output_features:\n",
    "  - name: Issue\n",
    "    type: text\n",
    "\n",
    "trainer:\n",
    "  type: finetune\n",
    "  learning_rate: 0.0001\n",
    "  batch_size: 1\n",
    "  gradient_accumulation_steps: 16\n",
    "  epochs: 3\n",
    "  learning_rate_scheduler:\n",
    "    decay: cosine\n",
    "    warmup_fraction: 0.01\n",
    "\n",
    "preprocessing:\n",
    "  sample_ratio: 0.1\n",
    "\n",
    "```\n",
    "A few of the key parameters set are outlined below:\n",
    "- `model_type`: this indicates that we want to train an LLM model instead of an ECD or GBM model.\n",
    "- `base_model`: this is the open source model that we will be fine-tuning\n",
    "- `quantization`: this parameter specifies the level of quantization to use during the fine-tuning process. Different levels of quantization tell Predibase to use more memory efficient calculations method which allows us to fine-tune on cheaper more widely available hardware. The tradeoff is time as lower levels of quantization tend to take longer to complete the fine-tuning process.\n",
    "- `adapter.type`: this indicates the method of parameter efficient fine tuning (PEFT) we want to use.\n",
    "- `prompt.template`: here we are providing a prompt template that extracts the specfied values from the dataset for every row and constructs a prompt that is fed to the model. By being very explicit here, we can help the model achieve better performance.\n",
    "- `preprocessing.sample_ratio`: this parameter tells Predibase to only use a subset of the dataset to train. This dataset has ~1 million rows, but we only need about 1000 to fine-tune.\n",
    "\n",
    "For more configuration details, check out the [Ludwig LLM Docs](https://ludwig.ai/0.8/configuration/large_language_model/)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb0557-7fd9-45ce-86e5-2c2d5d41a530",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_complaints_config = {\n",
    "    'model_type': 'llm',\n",
    "    'base_model': 'meta-llama/Llama-2-7b-hf',\n",
    "    'quantization': {\n",
    "        'bits': 4\n",
    "    },\n",
    "    'adapter': {\n",
    "        'type': 'lora'\n",
    "    },\n",
    "    'prompt': {\n",
    "        'template': \"\"\"\n",
    "            Given the following real world consumer complaint received about a financial product or service, classify the issue type:\n",
    "            Consumer Complaint: {Consumer complaint narrative}\n",
    "            Product: {Product}\n",
    "            Sub-Product: {Sub-product}\n",
    "            Issue Type:\n",
    "            \"\"\"\n",
    "    },\n",
    "    'input_features': [\n",
    "        {'name': 'Consumer complaint narrative', 'type': 'text'}\n",
    "    ],\n",
    "    'output_features': [\n",
    "        {'name': 'Issue', 'type': 'text'}\n",
    "    ],\n",
    "    'trainer': {\n",
    "        'type': 'finetune',\n",
    "        'learning_rate': 0.0001,\n",
    "        'batch_size': 1,\n",
    "        'gradient_accumulation_steps': 16,\n",
    "        'epochs': 3,\n",
    "        'learning_rate_scheduler': {\n",
    "            'decay': 'cosine', \n",
    "            'warmup_fraction': 0.01\n",
    "        }\n",
    "    },\n",
    "    'preprocessing': {\n",
    "        'sample_ratio': 0.1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed25dcc-fbe3-4298-81b7-9b219f8a8e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_complaints_model = pc.create_model(\n",
    "    repository_name=\"Fine-tuning Consumer Complaints\", \n",
    "    dataset=consumer_complaints_dataset, \n",
    "    config=consumer_complaints_config, \n",
    "    engine=train_engine,\n",
    "    model_description=\"Basic Fine-tuning LLaMa2-7B on Consumer Complaints\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
